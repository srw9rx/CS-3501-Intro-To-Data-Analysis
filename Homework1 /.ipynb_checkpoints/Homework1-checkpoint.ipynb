{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "actual-rescue",
   "metadata": {},
   "source": [
    "Sophia Walton - srw9rx\n",
    "CS 3501 - Foundations of Data Analysis \n",
    "Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-zimbabwe",
   "metadata": {},
   "source": [
    "1. Say 12% of the population is rich, 8% of the population is famous, and 6% of the population\n",
    "is both rich and famous. Define events R = “person is rich” and F = “person is famous”\n",
    "for some randomly selected person in the population. Write an expression for each of the\n",
    "following events using set operations involving the events R and F. Here you can just give\n",
    "the answer, and do not need to show any work.\n",
    "Example: “The person is rich and famous” would be the event R ∩ F.\n",
    "(a) The person is not famous.\n",
    "(b) The person is rich but not famous.\n",
    "(c) The person is either rich or famous (or both).\n",
    "(d) The person is neither rich nor famous."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-satisfaction",
   "metadata": {},
   "source": [
    "a. P(F^c)\n",
    "\n",
    "b. P(R $\\cap$ $F^c$)\n",
    "\n",
    "c. P(R $\\cup$ F)\n",
    "\n",
    "d. P($R^c$ $\\cap$ $F^c$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "established-parking",
   "metadata": {},
   "source": [
    "2. Calculate the probabilities for each of the four events in the previous problem. Be sure to\n",
    "show your intermediate steps and list any probability rules that you use.\n",
    "Example: The probability for “The person is rich and famous” would be P(R ∩ F) = 0.06."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-pearl",
   "metadata": {},
   "source": [
    "a. P(F^c)=1-P(F)=1-0.08=92%\n",
    "I arrived at this via the complement rule of probability. \n",
    "\n",
    "b. P(R $\\cap$ $F^c$)=P(R)-P(R $\\cap$ F)=0.12-0.06 = 6%\n",
    "I arrived at this via the complement rule of probability and the exclusion principle of probability.\n",
    "\n",
    "c. P(R $\\cup$ F)=P(R)+P(F)-P(R $\\cap$ F)=0.12+0.08-0.06=14%\n",
    "I arrived at this conclusion through the definition of exclusion in probability. \n",
    "\n",
    "d. P($R^c$ $\\cap$ $F^c$) =1 - P(R $\\cup$ F)= 1-0.14 = 86%\n",
    "I arrived at this via the complement rule of probability being applied multiple times as well as by referencing the methods used for answering the previous part of the question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-company",
   "metadata": {},
   "source": [
    "3. You have two black socks, two white socks, two red socks, and two blue socks in your sock\n",
    "drawer. If you pick two socks out at random (without looking!), what is the probability that\n",
    "they match? Explain how you arrived at the answer, don’t just give a number!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-empire",
   "metadata": {},
   "source": [
    "Events: Pulling a black sock = A; Pulling a White sock = B; Pulling a red sock = C; Pulling a blue sock =D\n",
    "P(match)=P(AA)+P(BB)+P(CC)+P(DD)\n",
    "\n",
    "=($\\frac{1}{4}$)($\\frac{1}{7}$)+($\\frac{1}{4}$)($\\frac{1}{7}$)+($\\frac{1}{4}$)($\\frac{1}{7}$)+($\\frac{1}{4}$)($\\frac{1}{7}$)\n",
    "\n",
    "=4($\\frac{1}{4}$)($\\frac{1}{7}$)\n",
    "\n",
    "=4($\\frac{1}{28}$)\n",
    "\n",
    "=$\\frac{1}{7}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-tulsa",
   "metadata": {},
   "source": [
    "4. According to the American Lung Association, there is a 0.13% chance to develop lung cancer.\n",
    "Of the people who have lung cancer, 90% of them are smokers. In the population of people\n",
    "who do not have lung cancer, 16.9% are smokers.\n",
    "(a) What percentage of the total population are smokers?\n",
    "(b) If you are a smoker, what is your probability to develop lung cancer?\n",
    "(c) If you are not a smoker, what is your probability to develop lung cancer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-disco",
   "metadata": {},
   "source": [
    "given:\n",
    "P(C)=0.0013\n",
    "P(S|C)=0.9\n",
    "P(S|$C^c$) = 0.169\n",
    "\n",
    "a. P(S) = P(S|C)*P(C) + P(S|$C^c$)P($C^c$)\n",
    "\n",
    "=0.9(0.0013)+(0.169)(1-0.0013)=0.9(0.0013)+(0.169)(0.87)\n",
    "\n",
    "=0.16995\n",
    "\n",
    "b. P(C|S) = $\\frac{P(S|C)*P(C)}{P(S)}$\n",
    "\n",
    "= 0.9*0.0013/0.16995\n",
    "\n",
    "= 0.00688\n",
    "\n",
    "c. P(C|$S^C$) = P$\\frac{P(S^C|C)*P(C)}{P(S^C)}$\n",
    "\n",
    "=$\\frac{(1-P(S|C)*P(C)}{(1-P(S)}$\n",
    "\n",
    "= (0.1)(0.0013)/0.83005\n",
    "\n",
    "= 0.000157"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-offering",
   "metadata": {},
   "source": [
    "5. In this exercise we will be using data from the OASIS brain database, a publicly-available\n",
    "resource:\n",
    "http://www.oasis-brains.org\n",
    "You will be classifying dementia from the volume of the hippocampus, a brain structure that\n",
    "is critical to memory. The data you will use is in the spreadsheet OASIS-hippocampus.csv,\n",
    "which you can download from the class website. The data consists of the hippocampal volume,\n",
    "derived from MRI, for elderly subjects, including healthy control subjects and those with mild\n",
    "to moderate dementia. Model the right hippocampal volume (RightHippoVol) as a normal\n",
    "random variable X1 and the left hippocampal volume (LeftHippoVol) as a normal random\n",
    "variable X2. Then model the diagnosis (Dementia) as a binary random variable Y (Y = 0:\n",
    "healthy control, Y = 1: dementia). Use the training subset of the data (TrainData = 1) to\n",
    "learn the mean and variance parameters for a na¨ıve Bayes classifier. Finally, apply your na¨ıve\n",
    "Bayes classifier to get a probabilistic diagnosis of the test subset of the data (TrainData = 0).\n",
    "Do the following:\n",
    " Plot the data as a 2D scatterplot (right and left hippocampal volume as the two axes).\n",
    "Use two different colors for the two classes (healthy/dementia). Do you think there is\n",
    "separation between the two classes?\n",
    " Plot two density plots for the left and right hippocampus volumes. Again, plot a different\n",
    "density for the two classes (with the same colors as your scatterplot).\n",
    " Run your classifier on the testing data. For each data point, if your classifier probability\n",
    "is greater than 0.5, predict that it is a dementia patient. Then compare with the actual\n",
    "label to see if your classifier is correct. Report your classifier accuracy on the testing\n",
    "data (number of correct classifications divided by size of the test data).\n",
    "Note: There are Python machine learning libraries that include a method for na¨ıve Bayes.\n",
    "You can’t use these to solve this problem! You have to write your own code to implement\n",
    "na¨ıve Bayes. However, it’s okay to try out a library’s version to check if it gives a similar\n",
    "answer to your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "color-nancy",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/sophiawalton/Desktop/CS3501/Homework 1/OASIS-hippocampus.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a1c11f45e4a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#import the csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mhippocampus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/sophiawalton/Desktop/CS3501/Homework 1/OASIS-hippocampus.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#create a dataframe of the right hippocampus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/sophiawalton/Desktop/CS3501/Homework 1/OASIS-hippocampus.csv'"
     ]
    }
   ],
   "source": [
    "#import statements \n",
    "from matplotlib import pyplot as plt \n",
    "from scipy.stats import norm \n",
    "import pandas \n",
    "import numpy as np\n",
    "\n",
    "#import the csv\n",
    "hippocampus = pandas.read_csv('/Users/sophiawalton/Desktop/CS3501/Homework1/OASIS-hippocampus.csv', header=0)\n",
    "\n",
    "#create a dataframe of the right hippocampus \n",
    "rightVolume = pandas.DataFrame(hippocampus, columns= ['RightHippoVol'])\n",
    "leftVolume = pandas.DataFrame(hippocampus, columns =['LeftHippoVol'])\n",
    "#print (rightVolume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-mistress",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create important statistics for right hippocampus volume (normal distribution)\n",
    "meanRight = rightVolume['RightHippoVol'].mean()\n",
    "sdRight = rightVolume['RightHippoVol'].std()\n",
    "minRight = rightVolume['RightHippoVol'].min()\n",
    "maxRight = rightVolume['RightHippoVol'].max()\n",
    "\n",
    "#create important statistics for left hippocampus volume (normal distribution)\n",
    "meanLeft = leftVolume['LeftHippoVol'].mean()\n",
    "sdLeft = leftVolume['LeftHippoVol'].std()\n",
    "minLeft = leftVolume['LeftHippoVol'].min()\n",
    "maxLeft = leftVolume['LeftHippoVol'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "local-expression",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'minRight' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-aaf10063f1fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#create the range for graphing (right volume)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrightranges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminRight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxRight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgraphbaseright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrightranges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeanRight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msdRight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#create the range for graphing (left volume)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'minRight' is not defined"
     ]
    }
   ],
   "source": [
    "#create the range for graphing (right volume)\n",
    "rightranges = np.arange(minRight, maxRight, 1)\n",
    "graphbaseright = norm.pdf(rightranges, meanRight, sdRight)\n",
    "\n",
    "#create the range for graphing (left volume)\n",
    "leftranges = np.arange(minLeft, maxLeft, 1)\n",
    "graphbaseleft = norm.pdf(leftranges, meanLeft, sdLeft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-combining",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build plot of X1 \n",
    "fig, x1 = plt.subplots(figsize=(9,6))\n",
    "plt.style.use('fivethirtyeight')\n",
    "x1.plot(rightranges,graphbaseright)\n",
    "\n",
    "x1.set_xlim([minRight,maxRight])\n",
    "x1.set_xlabel('hippocampus volume')\n",
    "x1.set_yticklabels([])\n",
    "x1.set_title('X1 - Gaussian Distribution of Right Hippocampus Volume')\n",
    "\n",
    "#plt.savefig('normal_curve.png', dpi=72, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "#build plot of X2 \n",
    "fig, x2 = plt.subplots(figsize=(9,6))\n",
    "plt.style.use('fivethirtyeight')\n",
    "x2.plot(leftranges, graphbaseleft)\n",
    "\n",
    "x2.set_xlim([minLeft,maxLeft])\n",
    "x2.set_xlabel('hippocampus volume')\n",
    "x2.set_yticklabels([])\n",
    "x2.set_title('X2 - Gaussian Distribution of Left Hippocampus Volume')\n",
    "\n",
    "#plt.savefig('normal_curve.png', dpi=72, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-confidentiality",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data frame with the information required to group \n",
    "dementiadata = pandas.DataFrame(hippocampus, columns =[\"RightHippoVol\", \"LeftHippoVol\", \"TrainData\", \"Dementia\"])\n",
    "trainingData = dementiadata.groupby('TrainData').get_group(1).groupby('Dementia')\n",
    "\n",
    "#create training groups of dementia and healthy \n",
    "trainingdementia = trainingData.get_group(1)\n",
    "traininghealth = trainingData.get_group(0)\n",
    "\n",
    "#create testing group\n",
    "testingdata = dementiadata.groupby('TrainData').get_group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-eleven",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create classifier statistics from information \n",
    "print(\"Important Statistics about the Classes: \")\n",
    "#left hippocampus, dementia\n",
    "demMeanLeft = trainingdementia['LeftHippoVol'].mean()\n",
    "demVarLeft = trainingdementia['LeftHippoVol'].var()\n",
    "demMinLeft = trainingdementia['LeftHippoVol'].min()\n",
    "demMaxLeft = trainingdementia['LeftHippoVol'].max()\n",
    "\n",
    "print(\"\\n dementia mean left\", demMeanLeft, \"\\n dem Var Left\", demVarLeft, \"\\n dementia min left\", demMinLeft, \"\\n dementia max left\", demMaxLeft)\n",
    "\n",
    "#right hippocampus, dementia\n",
    "demMeanRight = trainingdementia['RightHippoVol'].mean()\n",
    "demVarRight = trainingdementia['RightHippoVol'].var()\n",
    "demMinRight = trainingdementia['RightHippoVol'].min()\n",
    "demMaxRight = trainingdementia['RightHippoVol'].max()\n",
    "\n",
    "print(\"\\n dementia mean Right\", demMeanRight, \"\\n dementia var right\", demVarRight, \"\\n dementia min Right\", demMinRight, \"\\n dementia max Right\", demMaxRight)\n",
    "\n",
    "#left hippocampus, healthy\n",
    "healthMeanLeft = traininghealth['LeftHippoVol'].mean()\n",
    "healthVarLeft = trainingdementia['LeftHippoVol'].var()\n",
    "healthMinLeft = traininghealth['LeftHippoVol'].min()\n",
    "healthMaxLeft = traininghealth['LeftHippoVol'].max()\n",
    "\n",
    "print(\"\\n healthy mean left\", healthMeanLeft, \"\\n healthy var left\", healthVarLeft,\"\\n healthy min left\", healthMinLeft, \"\\n health max left\", healthMaxLeft)\n",
    "\n",
    "#right hippocampus, healthy\n",
    "healthMeanRight = traininghealth['RightHippoVol'].mean()\n",
    "healthVarRight = traininghealth['RightHippoVol'].var()\n",
    "healthMinRight = traininghealth['RightHippoVol'].min()\n",
    "healthMaxRight = traininghealth['RightHippoVol'].max()\n",
    "\n",
    "print(\"\\n healthy mean Right\", healthMeanRight, \"\\n healthy var right\", healthVarRight,\"\\n healthy min Right\", healthMinRight, \"\\n healthy max Right\", healthMaxRight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-universal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot scatterplot of training data \n",
    "fig, ytrain = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ytrain.scatter(x = trainingdementia['RightHippoVol'], y = trainingdementia['LeftHippoVol'], color ='red')\n",
    "ytrain.scatter(x = traininghealth['RightHippoVol'], y = traininghealth['LeftHippoVol'], color ='blue')\n",
    "plt.xlabel(\"right hippocampus volume\")\n",
    "plt.ylabel(\"left hippocampus volume\")\n",
    "plt.title(\"Training Data Scatterplot of Hippocampus Volume\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-rental",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create normal classifier part \n",
    "from math import sqrt, exp, pi\n",
    "num_dem = trainingData.sum()\n",
    "\n",
    "def create_classifier(x, var, mean):\n",
    " exponent = exp(-((x-mean)**2 / (2 * var )))\n",
    " return (1 / (sqrt(2 * pi) * sqrt(var))) * exponent\n",
    "\n",
    "def classifying(i, demvar, demmean, healthv, healthm):\n",
    "    returnlist = []\n",
    "    for item in i:\n",
    "        prob_xgivendementia = create_classifier(item, demvar, demmean)\n",
    "        prob_xgivenhealthy= create_classifier(item, healthv, healthm)\n",
    "        pofx = prob_xgivendementia*(0.5)+prob_xgivenhealthy*(0.5)\n",
    "        pofdementia=(prob_xgivendementia*0.5)/pofx\n",
    "        pofhealthy=(prob_xgivenhealthy*0.5)/pofx\n",
    "        if (pofdementia>0.5):\n",
    "            returnlist.append(1)\n",
    "        else:\n",
    "            returnlist.append(0)  \n",
    "    return returnlist;   \n",
    "        \n",
    "#left hippocampus\n",
    "dementiaFromLeft = classifying(testingdata['LeftHippoVol'], demVarLeft, demMeanLeft, healthVarLeft, healthMeanLeft)\n",
    "#leftadded = testingdata.assign(leftdata = dementiaFromLeft)\n",
    "\n",
    "#right hippocampus \n",
    "dementiaFromRight = classifying(testingdata['RightHippoVol'], demVarRight, demMeanRight, healthVarRight, healthMeanRight)\n",
    "leftandright = testingdata.assign(rightdata = dementiaFromRight).assign(leftdata = dementiaFromLeft)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specified-morris",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot of left testing data\n",
    "leftplotdementia = leftandright.groupby('leftdata').get_group(1)\n",
    "leftplothealthy= leftandright.groupby('leftdata').get_group(0)\n",
    "fig, leftplot = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "leftplot.scatter(leftplotdementia['RightHippoVol'], leftplotdementia['LeftHippoVol'],color ='red')\n",
    "leftplot.scatter(leftplothealthy['RightHippoVol'], leftplothealthy['LeftHippoVol'], color ='blue')\n",
    "plt.xlabel(\"right hippocampus volume\")\n",
    "plt.ylabel(\"left hippocampus volume\")\n",
    "plt.title(\"Testing Data Scatterplot of Hippocampus Volume (from left)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-superior",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot of right testing data\n",
    "rightplotdementia = leftandright.groupby('rightdata').get_group(1)\n",
    "rightplothealthy= leftandright.groupby('rightdata').get_group(0)\n",
    "fig, leftplot = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "leftplot.scatter(rightplotdementia['RightHippoVol'], rightplotdementia['LeftHippoVol'],color ='red')\n",
    "leftplot.scatter(rightplothealthy['RightHippoVol'], rightplothealthy['LeftHippoVol'], color ='blue')\n",
    "plt.xlabel(\"right hippocampus volume\")\n",
    "plt.ylabel(\"left hippocampus volume\")\n",
    "plt.title(\"Testing Data Scatterplot of Hippocampus Volume (from right)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-major",
   "metadata": {},
   "outputs": [],
   "source": [
    "#actual plot\n",
    "\n",
    "actualdem = leftandright.groupby('Dementia').get_group(1)\n",
    "actualh= leftandright.groupby('Dementia').get_group(0)\n",
    "fig, actualplot = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "actualplot.scatter(actualdem['RightHippoVol'], actualdem['LeftHippoVol'],color ='red')\n",
    "actualplot.scatter(actualh['RightHippoVol'], actualh['LeftHippoVol'], color ='blue')\n",
    "plt.xlabel(\"right hippocampus volume\")\n",
    "plt.ylabel(\"left hippocampus volume\")\n",
    "plt.title(\"Testing Data Scatterplot of Hippocampus Volume (actual values)\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print (\"\\n\")\n",
    "#all data \n",
    "alldata = pandas.DataFrame(hippocampus, columns =[\"RightHippoVol\", \"LeftHippoVol\", \"TrainData\", \"Dementia\"])\n",
    "dem_train= alldata.groupby(\"TrainData\").get_group(1).groupby(\"Dementia\").get_group(1)\n",
    "h_train= alldata.groupby(\"TrainData\").get_group(1).groupby(\"Dementia\").get_group(0)\n",
    "dem_test= alldata.groupby(\"TrainData\").get_group(0).groupby(\"Dementia\").get_group(1)\n",
    "h_test= alldata.groupby(\"TrainData\").get_group(0).groupby(\"Dementia\").get_group(0)\n",
    "\n",
    "#plot\n",
    "fig, allplot = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "allplot.scatter(dem_train['RightHippoVol'], dem_train['LeftHippoVol'],color ='red')\n",
    "allplot.scatter(h_train['RightHippoVol'], h_train['LeftHippoVol'], color ='blue')\n",
    "allplot.scatter(dem_test['RightHippoVol'], dem_test['LeftHippoVol'],color ='green')\n",
    "allplot.scatter(h_test['RightHippoVol'], h_test['LeftHippoVol'], color ='orange')\n",
    "plt.xlabel(\"right hippocampus volume\")\n",
    "plt.ylabel(\"left hippocampus volume\")\n",
    "plt.title(\"Scatterplot of Hippocampus Volume (all values - recorded)\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-nursing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier accuracy\n",
    "leftcorrect = 0;\n",
    "rightcorrect = 0;\n",
    "dementiaseries=pandas.Series(leftandright['Dementia'])\n",
    "leftseries = pandas.Series(leftandright['leftdata'])\n",
    "rightseries = pandas.Series(leftandright['rightdata'])\n",
    "\n",
    "leftequal=0\n",
    "rightequal=0\n",
    "for i in range(0, len(dementiaseries)):\n",
    "    if leftseries.at(i) == dementiaseries.at(i):\n",
    "        leftequal+=1\n",
    "    if rightseries.at(i) == dementiaseries.at(i):\n",
    "        rightequals+=1\n",
    "\n",
    "\n",
    "print(\"classifier accuracy for left is:\" , leftcorrect/225)\n",
    "print(\"classifier accuracy for right is:\", rightcorrect/225)\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-junction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
